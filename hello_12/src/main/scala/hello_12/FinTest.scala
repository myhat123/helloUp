/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package hello_12

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

object FinTest {
  def main(args: Array[String]) {
    val spark = SparkSession
      .builder
      .appName("写入clickhouse数据")
      .getOrCreate()
    
    import spark.implicits._

    val df = spark.read.options(Map("inferSchema"->"true","delimiter"->",","header"->"true"))
                        .csv("file:///home/hzg/work/helloUp/data-files/data.csv")
    df.createOrReplaceTempView("qry_dtl")

    val df2 = spark.sql("""
        select to_date(tran_date) as tran_date, timestamp1, acc, amt, dr_cr_flag, rpt_sum from qry_dtl
    """)

    // df2.show()
    df2.write
      .format("jdbc")
      .mode("append")
      .option("driver", "ru.yandex.clickhouse.ClickHouseDriver")
      .option("url", "jdbc:clickhouse://localhost:8123/finance")
      .option("user", "hzg")
      .option("password", "1234")
      .option("dbtable", "brch_qry_dtl")
      .option("batchsize", 10000)
      .option("isolationLevel", "NONE")
      .save

    spark.stop()
  }
}